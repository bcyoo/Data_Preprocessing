# -*- coding: utf-8 -*-
"""CNN_기본.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xpZh7viL6h4G-RjlvwTVV0-AN46Nc8KR

5. CNN을 이용한 분류 (CIFAR10)
    
    합성곱 신경망 (Convoluational Neural Network)를 이용한 이미지 분류
"""

import torch
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import matplotlib.pyplot as plt

"""5.1 CIFAR10 데이터 불러오기"""

from google.colab import drive
drive.mount('/content/gdrive')

cd/content/gdrive/MyDrive/deeplearningbro/pytorch

# CIFAR10 : 클래스 10개를 가진 이미지 데이터
# 'plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'

transform = transforms.Compose(
    [transforms.ToTensor(), ## 텐서 데이터 변경
     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) # 0.5,0.5,0.5 칼라이미지라 0채널 1채널 2채널에 평균과 표준편차를 정규화함

trainset = torchvision.datasets.CIFAR10(root='./data', train=True,
                                       download=True, transform=transform) #transform 이용해 전처리함

trainloader = torch.utils.data.DataLoader(trainset, batch_size=8, shuffle=True) # 데이터를 배치형태로하기 위해 DataLoader 이용함

testset = torchvision.datasets.CIFAR10(root='/data', train=False,
                                       download=True, transform=transform)

testloader = torch.utils.data.DataLoader(testset, batch_size=8, shuffle=False)

# CPU / GPU
device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
print(f'{device} is available.')

"""5.2 CNN 모델 구축"""

class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(3, 6, 5) # 합성곱 연산 (입력 채널수 3, 출력 채널수 6, 필터크기 5x5, stride=1(defualt)) / 칼라 이미지이기에 채널수3, 사용자에따라 임의로 출력 6개설정
        self.pool1 = nn.MaxPool2d(2, 2) # 합성곱 연산 (필터 크기 2, stride=2)
        self.conv2 = nn.Conv2d(6, 16, 5) # 합성곱 연산 (입력 채널수 6, 출력 채널수 16, 필터크기 5x5. stride=1(defualt))
        self.pool2 = nn.MaxPool2d(2, 2) # 합성곱 연산 (필터 크기 2, stride=2)
        self.fc1 = nn.Linear(16 * 5 * 5, 120) # 5x5 피쳐맵 16개를 일려로 피면 16*5*5개의 노드가 생성 
        self.fc2 = nn.Linear(120, 10) # 120개 노드에서 클래스의 개수인 10개의 노드로 연산 / 10개 이미지이기에 10개의 노드가 되어야함


    def forward(self, x):
        x = self.pool1(F.relu(self.conv1(x))) # conv1 -> ReLU -> pool1
        x = self.pool2(F.relu(self.conv2(x))) # conv2 -> RuLU -> pool2
        x = x.view(-1, 16*5*5) # 5*5 피쳐맵 16개를 일렬로 만든다 / x를 view함수로 일렬로 펴줌
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))

        return x

net = Net().to(device) # 모델 선언

print(net)
# 32 -> 28 -> 14 -> 10 -> 5

"""5.3 모델 학습하기"""

criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(net.parameters(), lr=1e-3, momentum=0.9)

# 모델의 학습 과정 4강과 동일
loss_ = [] # 그래프를 그리기 위한 loss 저장용 리스트

n = len(trainloader) # 배치 개수

for epoch in range(10): # 10번 학습

    running_loss = 0.0
    for i, data in enumerate(trainloader, 0):
        
        inputs, labels = data[0].to(device), data[1].to(device) # 배치 데이터

        optimizer.zero_grad()

        outputs = net(inputs) # 예측 값 산출
        loss = criterion(outputs, labels) # 손실함수 계산
        loss.backward() #손실함수 기준 으로역전파 선언
        optimizer.step() # 가중치 최적화

        # print statustics
        running_loss += loss.item()

    loss_.append(running_loss / n )
    print('[%d] loss: %.3f' %(epoch + 1, running_loss / len(trainloader)))

print ('Finished Training')

plt.plot(loss_)
plt.title('Training Loss')
plt.xlabel('epoch')
plt.show

"""5.4 모델 저장하기"""

PATH = './cifar_net.pth' #모델 저장 경로
torch.save(net.state_dict(), PATH) # 모델 저장

"""5.5. 모델 불러오기"""

# 모델 불러오기는 모델의 파라메타를 불러오는 것, 따라서 모델의 뼈대를 먼저 선언함 Net().to(device)
# 모델의 파라메타를 불러와 pretrainde model을 만든다

net = Net().to(device) #모델선언
net.load_state_dict(torch.load(PATH))

"""5.6 모델 정확도 """

# 평가 데이터를 이용해 정확도를 구해보자
# output은 미니배치의 결과가 산출되기 때문에 for문을 통해서 test 전체의 예측값을 구함

correct = 0
total = 0
with torch.no_grad():
    for data in testloader:
        images, labels = data[0].to(device), data[1].to(device)
        outputs = net(images)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0) # 개수 능력( 총 개수)
        correct += (predicted == labels).sum().item() #  누적(맞으면 1, 틀리면 0으로 합산)

print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct/ total))

