# -*- coding: utf-8 -*-
"""Pytorch_데이터_불러오기.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-vBDWOsRM2MX6OkLu6vw9BL9dtWZZVhd

3. 데이터 불러오기

    딥러닝을 포함한 머신러닝의 근원은 데이터다.
    따라서 데이터의 수집, 가공, 사용 방법에 따라 모델 성능이 크게 달라질 수     있으며 데이터의 형태는 매우 다양하기 때문에 데이터를 잘 불러오는 것은 가장 중요한 단계 중 하나다.
"""

import torch
import torchvision # 이미지 관련 파이토치 라이브러리
import torchvision.transforms as tr # 이미지 전처리 기능 제공 라이브러리
from torch.utils.data import DataLoader, Dataset # 데이터를 모델에 사용할수 있도록 정리해주는 라이브러리
import numpy as np

"""3.1 파이토치 제공 데이터 사용"""

# tr.Compose 내에 원하는 전처리르 차례로 넣어주면 된다 

transf = tr.Compose([tr.Resize(16),        # 16x16으로 이미지 크기 변환 후 텐서 타입으로 변환
                     tr.ToTensor()
                     ])      
# 전처리 방법 
# Transforms on PIL Image
# Pad, Grayscale, RandomCrop, Normalize ..
# Transforms on torch.*Tensor = tensor image
# torchvision.transforms.ToPILImage(mode=None)..
# ...

# https://pytorch.org/docs/stable/torchvision/datasets.html에서 다양한 이미지 데이터셋을 확인 가능
# torchvision.datases에서 제공하는 CIFAR10 데이터를 불러온다.
# root에는 다운로드 받을 경로를 입력한다.
# train=True 면 학습 데이터를 불러오고 train=False면 테스트 데이터를 불러온다.
# 미리 선언한 전처리를 사용하기 위해 trsnform=transf을 작성한다.

trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transf)  # 전처리되는 함수 transf를 transform에 넣어줌
testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transf)

# 일반적으로 데이터셋은 이미지와 라벨 형식이 동시에 들어있는 tuple 형태이다. (이미지, 라벨)
# trainset[0]은 학습 데이터의 첫 번째 데이터로 이미지 한장고 ㅏ라벨 숫자 하나가 저장되어있다.
# 즉 trainset[0][0]은 이미지이며 trainset[0][1]은 라벨이다.

print(trainset[0][0].size())

# 현재 이미지 사이즈는 3x16x16이다. 여기서 3은 채널의 수를 말하고 16x16은 이미지의 너비와 높이를 의미한다.
# 일반적인 컬러사진은 RGB이미지이기 때문에 채널이 3개이고 (너비)x(높이)x(채널 수)로 크기가 표현된다.

# 하지만 파이토치에서는 이미지 한 장이 (채널수)x(너비)x(높이) 순으로 표현되는 것을 기억해야함
# 채널3 너비16 높이 16

# Dataloader는 데이터를 미니 배치 형태로 만들어 준다.
# 따라서 배치 사이즈 및 셔플 여부 등을 선택할 수 있다.

trainloader = DataLoader(trainset, batch_size=50, shuffle=True) # DataLoader를 통해 딥러닝 모델에 사용할 수 있도록 batch 형태로 변경해줘야함
testloader = DataLoader(testset, batch_size=50, shuffle=False) # testloader는 학습을 안함 batch_size에 5만개를 넣어도 되지만 메모리 문제가 발생할 수있기 때문에 50으로 해줌
                                                               # test에서 suffle은 필요없음.
# batch_size = 50 은 이미지가 한번 학습할 때마다 이미지 50개씩 들어가서 학습. /shuffle=True 는 이미지를 섞어서 한다는 의미.

len(trainloader)
#  CIFA10의 학습 이미지는 50,000장이고 배치 사이즈가 50이므로 1000장은 배치의 개수가 된다.
# 즉 trainloader가 잘 만들어졌다는 것을 단편적으로 알 수 있음.

# iter, next 를 이용해 일부 데이터를 확인할 수 있다.
dataiter = iter(trainloader)
images, labels = dataiter.next()

print (images.size())
# 일반적으로 학습 데이터는 4차원 형태로 모델에서 사용됨.
# (배치 크기) x (채널 수) x (너비) x (높이)
# 배치가 잘 나눠져 있음을 확인 할수 있음.

"""## 우리가 직접 데이터를 활용 할 때 사용 하는 방법.

3.2 같은 클래스 별로 폴더를 정리한 경우


"""

# 데이터가 같은 클래스 별로 미리 폴더를 정리 된 경우, ImageFolder의 1줄 선언으로 개인 데이터를 사용할 수 있다.
# 별도의 라벨링이 필요 없으며 폴도 별로 자동으로 라벨링을 한다.
# 예를 들어 class 폴더에 tiger, lion 폴더(./calss/tiger와 ./class/lion)를 미리 만든다.
# 다음으로 ImageFolder에 상위 폴더 ./class를 입력하면 이미지와 라벨이 정리되어 데이터를 불러온다.

transf = tr.Compose([tr.Resize(128),
                     tr.ToTensor()]) # 128x128 이미지 크기 변환 후 텐서로 만든다.

trainset = torchvision.datasets.ImageFolder(root='/content/drive/MyDrive/deeplearningbro/pytorch/class', transform=transf) #커스텀 데이터를 불러온다. # 전처리되는 함수 transf를 transform에 넣어줌

trainloader = DataLoader(trainset, batch_size=1, shuffle=False) # 데이터를 미니 배치 형태로 만들어준다.
 # DataLoader를 통해 딥러닝 모델에 사용할 수 있도록 batch 형태로 변경해줘야함
 # batch_size = 50 은 이미지가 한번 학습할 때마다 이미지 50개씩 들어가서 학습. /shuffle=True 는 이미지를 섞어서 한다는 의미.

"""3.3 정형화 되지 않는 커스텀 데이터 불러오기

1) 라벨 별로 폴더 저리가 되어 있지 않는 경우 \
2) 다른 작업들과 공유된 데이터인 경우 \
3) 이미지 데이터가 텍스트,리스트,배열 등으로 저장되어있는 경우
"""

# 32x32 컬러 이미지와 라벨이 각각 100장 있다고 가정.

train_images = np.random.randint(256, size=(100,32,32,3)) # (이미지 수)x(너비)x(높이)x(채널 수)
train_labels = np.random.randint(2, size=(100,1)) #라벨 수


# 이미지 전처리 작업이 필요할 경우 OpenCV 같은 라이버러리를 이용하여 이 곳에서 작업 가능
# torchvision.transforms 라이브러리 보다 OpenCV, SciPY와 같은 라이브러리가 더 많은 전처리 기술 제공하며 이미지를 미리 처리 해놓고 전처리된 이미지를 살펴보면서
# 작업하는 것이 가능. 따라서 사용 목적과 편의성에 맞게 전처리를 어디서 할지 정하면 될것이다.


#....
#....
# train_images, train_labels = preprocessing(train_imagesm train_labels)
#....
#....
#....

print(train_images.shape, train_labels.shape)

# 전처리 후 data를 사용할 수 있께 tensor dataset으로 변경하는 양식

'''
from torch.utils.data import Dataset

class MyDataset(Dataset): #Dataset을 class에 상속 시킴.

    def __init__(self):

    def __getitem__(self, index):

    def __len__(self):

'''

class TensorData(Dataset):

    def __init__(self, x_data, y_data): #x,y data를 풀러옴
        self.x_data = torch.FloatTensor(x_data) # x,y dat 이미지 데이터를 FloatTensor로 변경
        self.x_data = self.x_data.permute(0,3,1,2) # (이미지 수) x (너비) x (높이) x (채널 수) -> (배치 크기) x (채널 수) x (너비) x (높이)
        self.y_data = torch.LongTensor(y_data) # 라벨 데이터를 LongTensor로 변경
        self.len = self.y_data.shape[0] # 클래스 내의 들어온 데이터 개수

    def __getitem__(self, index):
        return self.x_data[index]. self.y_data[index] # 뽑아 낼 데이터를 적어준다.

    def __len__(self):
        return self.len # 클래스 내의 들어온 데이터 개수

# pytorch 에서는 (배치크기) x (채널 수) x (너비) x (높이) 데이터가 사용되므로 원래 데이터 (이미지수)x(너비)x(높이)x(채널 수)를 변경해줘야함
# permute에서 0(이미지수),1(너비),2(높이),3(채널 수)을 0(이미지 수), 3(채널수), 1(너비),2(높이)로 바꿔주는 것임
# .permute(0,3,1,2)을 사용

train_data = TensorData(train_images, train_labels) # 텐서 데이터 불러오기
train_loader = DataLoader(train_data, batch_size=10, shuffle=True) # 미니 배치 형태로 데이터 갖추기

