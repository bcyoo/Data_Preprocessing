# -*- coding: utf-8 -*-
"""Pytorch_입문.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EvHelLbPncplT2aGQrVRQsBtYIlE5tjp

1. Tensor

Tensor는 Pytorch의 기본 단위이며 GPU 연산을 가능하게 한다.
또한 Numpy 배열과 유사하다.

1.1 Tensor 만들기
"""

# 라이브러리

import torch 
import numpy as np

# 빈 텐서 생성

x = torch.empty(5,4) # 5x4 행렬 생성

print(x) # 초기화 되지 않는 행렬인 경우 해당 시점에 할단된 메모리에 존재하던 값들이 초기값으로 나타난다.

torch.ones(3,3)  # 3x3 1로 이루어진 행열

torch.zeros(2) # 2행 0 vector

torch.rand(5,6) # 5x6 random 행렬

"""1.2 리스트 넘파이 배열을 텐서로 만들기."""

l = [13,4]  # 리스트 생성
r = np.array([4,56,7]) # 넘파이 배열 생성

torch.tensor(l)  # 리스트를 텐서로 쉽게 변환 가능

torch.tensor(r) # 넘바이 배열을 텐서로 쉽게 변환 가능

"""1.3 텐서의 크기와 타입 확인하기"""

x.size() # .size()는 텐서의 크기를 확인할 수 있으며 자주 사용된다.

type(x) # type는 python에서 사용되는 모든 것에 종류를 보여줌

"""1.4 텐서의 덧셈"""

x = torch.rand(2,2) # 2x2 랜덤 행렬
y = torch.rand(2,2) # 2x2 랜덤 행렬
print(x)
print(y)

x+y # 두 텐서의 합

torch.add(x,y) # 투 텐서의 합

y.add(x)

print('원래 y: ',y)
y.add_(x) # y에 x를 더해서 출력 _ 때문에 inplace가됨
print('y=y+x: ',y)
# y.add_는 y에 x를 더한 값을 y에 대체(inplace방식)

"""1.5 텐서의 크기 변환하기"""

x = torch.rand(8,8) #8x8 랜덤 행렬 생성
print(x.size())

a = x.view(64) ## 크기를 바꿔주는 view 8x8 -> 64로 바뀜 (크기가 바뀔 때 64개는 유지되어야함.)
print(a.size())

b = x.view(-1, 4, 4) # -1은 원래 크기가 되게 하는 값 8x8 --> -1x4x4 즉. 4x4x4이다
print (b.size())
# 따라서 -1은 원래 크기가 되게하는 값으로 자동 지정되기 때문에 한 번만 사용할 수 있다.
# 예를 들어 x.view(-1,-1,4)와 같은 선언은 오류가 남.

"""1.6 텐서에서 넘파이로 만들기"""

x = torch.rand(8,8)
y = x.numpy() # .numpy로 매우 간단하게 넘파이 배열로 변경가능
print(y)

type(y)

"""1.7 단일 텐서에서 값으로 뽑아내기"""

x = torch.ones(1)
x

print(x)
print(x.item()) # .item()은 손실 함수값과 같이 숫자가 하나인 텐서를 텐서가 아닌 값으로 만드러준다

"""2. 역전파
    인공 신경망을 최적화 하는 과정에서 미분을 필수적인 요소이다.
    pytorch는 최적화 과정인 역전파(backpropagation)을 쉽게 할 수 있도록      
    자동 미분 계산을 제공한다

2.1 자동 미분 준비하기
"""

import torch

# requires_grad = True는 해당 tensor를 기준으로 모든 연산들을 추적할 수 있게 하는 옵션.
# 즉, x에 대해서 연쇄 법칙을 이용한 미분이 가능하게하는 것

x = torch.ones(2,2, requires_grad=True) 
print (x)

# y는 x에 대한 식, z는 y에 대한 식, res는 z에 대한 식이다.
# 따라서 이는 합성함수의 개념으로써 x에 대해서 표현 및 미분이 가능하다.
y = x+1
z = 2*y**2
res = z.mean() 

print('y: ', y)
print('z: ', z)
print('Result: ',res)
# gran_fn = ..은 추적이 잘되고 있다는 의미다.
# x = torch.ones(2,2, requires_grad=True)는 x를 기준으로 x에 연관된 연산을 계속 추적함.

"""2.2 역전파"""

res.backward() # res를 기준으로 역전파를 진행하겠다는 의미.
# 역으로 식을 써내려 가보자.
# res = (z_1 + .. +z_4)/4
# z_i = 2 y_i **2
# z_i = 2(x_i+1)**2
# d(res)/dx_i = x_i +1

print(x)
print(x.grad)
# x.grad는 backward()가 선언 된 변수를 기준으로 미분한다. 즉 d(res)/dx를 계산함
# #d(res)/dx_i = x_i + 1